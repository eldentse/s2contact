<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>s2contact ECCV 2022</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Creative and Descriptive Paper Title." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">S<sup>2</sup>Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning</span>
		<table align=center width=600px>
			<table align=center width=1200px>
				<br>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:24px"><a href="https://eldentse.github.io/">Tze Ho Elden Tse<sup>*</sup></a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:24px"><a href="https://zhongqunzhang.github.io/">Zhongqun Zhang<sup>*</sup></a></span>
						</center>
					</td>
					<td align=center width=160px>
						<center>
							<span style="font-size:24px"><a href="https://sites.google.com/view/kimki">Kwang In Kim</a></span>
						</center>
					</td>
					<td align=center width=160px>
						<center>
							<span style="font-size:24px"><a href="https://www.cs.bham.ac.uk/~leonarda/">Ales Leonardis</a></span>
						</center>
					</td>
					<td align=center width=160px>
						<center>
							<span style="font-size:24px"><a href="https://faculty.sustech.edu.cn/fengzheng/en/">Feng Zheng</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:24px"><a href="https://hyungjinchang.wordpress.com/">Hyung Jin Chang</a></span>
						</center>
					</td>
				</tr>
			</table>
			<br>

			<center>
				<span style="font-size:20px">University of Birmingham, UNIST, SUSTech
					</span>
			</center>

			<center>
				<span style="font-size:20px">ECCV 2022
					</span>
			</center>
				
			</table>
			<br>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610561.pdf'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/eldentse/s2contact'>[Code]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<br>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:750px" src="./resources/Fig1.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					Overview of our semi-supervised learning framework, S<sup>2</sup>Contact. (a) The model
					is pre-trained on a small annotated dataset. (b) Then, it is deployed on unlabelled
					datasets to collect pseudo-labels. The pseudo-labels are filtered with confidence-based
					on visual and geometric consistencies. Upon predicting the contact map, the hand and
					object poses are optimised to achieve target contact via a contact model.
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Being able to reason about the physical contacts between
				hands and objects is crucial in understanding hand-object manipulation. However, despite the efforts in accurate 3D annotations in hand
				and object datasets, there still exist gaps in 3D hand and object reconstructions. Recent works leverage contact maps to refine inaccurate
				hand-object pose estimations and generate grasps given object models.
				However, they require explicit 3D supervision which is seldom available
				and therefore, are limited to constrained settings, e.g., where thermal
				cameras observe residual heat left on manipulated objects. In this paper, we propose a novel semi-supervised framework that allows us to
				learn contact from monocular videos. Specifically, we leverage visual and
				geometric consistency constraints in large-scale datasets for generating
				pseudo-labels in semi-supervised learning and propose an efficient graph-
				based network to infer contact. Our semi-supervised learning framework
				achieves a favourable improvement over the existing supervised learning
				methods trained on data with ‘limited’ annotations. Notably, our proposed model is able to achieve superior results with less than half the
				network parameters and memory access cost when compared with the
				commonly-used PointNet-based approach. We show benefits from using
				a contact map that rules hand-object interactions to produce more accurate reconstructions. We further demonstrate that training with pseudo-
				labels can extend contact map estimations to out-of-domain objects and
				generalise better across multiple datasets.
			</td>
		</tr>
	</table>
	<br>

<!-- 	<hr>
	<center><h1>Talk</h1></center>
	<p align="center">
		<iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
	</p> -->

<!-- 	<table align=center width=800px>
		<br>
		<tr>
			<center>
				<span style="font-size:28px"><a href=''>[Slides]</a>
				</span>
			</center>
		</tr>
	</table> -->
	<hr>

	<center><h1>Framework</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=600px>
				<center>
					<td><img class="round" style="width:950px" src="./resources/Fig2.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td align=center width=400px>
					A schematic illustration of our framework. We adopt our proposed graph-based network GCN-Contact
					as backbone. We utilise a teacher-student mutual learning framework which is composed of a learnable student and an EMA teacher. The student network is trained
					with labelled data. For unlabelled data, the student network takes pseudo
					contact labels from its EMA teacher and compares with its predictions. (a) refers to contact
					consistency constraint for consistency training. To improve the quality of pseudo-label,
					we adopt a confidence-based filtering mechanism to geometrically (b) and visually (c)
					filter out predictions that violate contact constraints.
				</td>
			</tr>
		</center>
	</table>
<!-- 	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/eldentse/collab-hand-object/'>[GitHub]</a>
			</center>
		</span>
	</table> -->
	<br>
	<hr>
	<table align=center width=800px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Tze Ho Elden Tse, Zhongqun Zhang, Kwang In Kim, Ales Leonardis, Feng Zheng and Hyung Jin Chang<br>
				<b>S<sup>2</sup>Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning</b><br>
				In ECCV, 2022.<br>
<!-- 				(hosted on <a href="">ArXiv</a>)<br> -->
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
<!-- 			<td align=center><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td> -->
				
			<td align=center><span style="font-size:14pt"><center>
				<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610561.pdf">[Paper]</a>
			</center></td>
			
			<td align=center><span style="font-size:14pt"><center>
				<a href="">[Supplementary]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This research was supported by the MSIT (Ministry of Science and ICT), Korea, under the ITRC 
					(Information Technology Research Center) support program (IITP--2022--2020--0--01789) supervised 
					by the IITP (Institute of Information \& Communications Technology Planning \& Evaluation) and 
					the Baskerville Tier 2 HPC service (https://www.baskerville.ac.uk/) funded by the Engineering 
					and Physical Sciences Research Council (EPSRC) and UKRI through the World Class Labs scheme (EP/T022221/1)
					and the Digital Research Infrastructure programme (EP/W032244/1) operated by Advanced Research Computing 
					at the University of Birmingham. KIK was supported by the National Research Foundation of Korea (NRF) 
					grant (No. 2021R1A2C2012195) and IITP grants (IITP--2021--0--02068 and IITP--2020--0--01336). ZQZ was 
					supported by China Scholarship Council (CSC) Grant No. 202208060266. AL was supported in part by the EPSRC 
					(grant number EP/S032487/1). FZ was supported by the National Natural Science Foundation of China under 
					Grant No. 61972188 and 62122035.
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

